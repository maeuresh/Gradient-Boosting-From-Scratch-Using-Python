# Gradient-Boosting-From-Scratch-Using-Python

This project implements the Gradient Boosting algorithm from scratch using Python. Gradient Boosting is an ensemble machine learning technique that builds multiple weak learners (typically decision trees) and combines them to form a strong predictive model. Unlike AdaBoost, which updates weights based on misclassifications, Gradient Boosting optimizes the model by minimizing the loss function via gradient descent.
